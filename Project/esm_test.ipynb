{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sequence_models.pretrained import load_model_and_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSATransformer(\n",
       "  (embed_tokens): Embedding(33, 768, padding_idx=1)\n",
       "  (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x AxialTransformerLayer(\n",
       "      (row_self_attention): NormalizedResidualBlock(\n",
       "        (layer): RowSelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (column_self_attention): NormalizedResidualBlock(\n",
       "        (layer): ColumnSelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward_layer): NormalizedResidualBlock(\n",
       "        (layer): FeedForwardNetwork(\n",
       "          (activation_fn): GELU(approximate='none')\n",
       "          (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=144, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)\n",
       "  (emb_layer_norm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (emb_layer_norm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model, alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmirmesic/opt/anaconda3/envs/cs144/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "url = \"https://elifesciences.org/download/aHR0cHM6Ly9jZG4uZWxpZmVzY2llbmNlcy5vcmcvYXJ0aWNsZXMvMTY5NjUvZWxpZmUtMTY5NjUtc3VwcDEtdjQueGxzelife-16965-supp1-v4.xlsx?_hash=UsG4XAO0qnBOtjEvbXpBgu%2FazhuWskkDqs417%2BIpaAM%3D\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "filepath = 'data/gb1data.xlsx'\n",
    "if not os.path.exists(filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "GB1_data = pd.read_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequences\n",
    "with open(\"data/GB1_Wu_2016.fasta\", \"r\") as f:\n",
    "    f.readline() # Skip the header\n",
    "    wildtype = f.read().replace(\"\\n\", \"\")\n",
    "\n",
    "sites = [39, 40, 41, 54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode sequences\n",
    "aa_list = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\",\"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
    "aa_to_onehot = {aa: np.eye(len(aa_list))[i] for i, aa in enumerate(aa_list)}\n",
    "# Create a one-hot encoding for the wild-type sequence\n",
    "onehot_wildtype = np.array([aa_to_onehot[aa] for aa in wildtype])\n",
    "\n",
    "def encode_mutants_onehot(row, onehot_wildtype):\n",
    "    mutant = onehot_wildtype.copy()\n",
    "    mutations = row['Variants']\n",
    "    for i, mutation in enumerate(mutations):\n",
    "        mutant[sites[i]-1] = aa_to_onehot[mutation]\n",
    "    return mutant\n",
    "def encode_sequence(row, wild):\n",
    "    mutant = list(wild)\n",
    "    mutations = row['Variants']\n",
    "    for i, mutation in enumerate(mutations):\n",
    "        mutant[sites[i]-1] = mutation\n",
    "    mutant = \"\".join(mutant)\n",
    "    return mutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149361/149361 [00:01<00:00, 124093.26it/s]\n",
      "100%|██████████| 149361/149361 [00:00<00:00, 235594.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply processing for dataframe to get sequence/onehot\n",
    "rows = len(GB1_data)\n",
    "tqdm.pandas(total=rows)\n",
    "GB1_data['onehot_sequence'] = GB1_data.progress_apply(lambda row: encode_mutants_onehot(row, onehot_wildtype), axis=1)\n",
    "GB1_data['full_sequence'] = GB1_data.progress_apply(lambda row: encode_sequence(row, wildtype), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNG<mask><mask><mask>EWTYDDATKTFT<mask>TE'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get masked sequence\n",
    "to_mask_sequence = list(wildtype)\n",
    "for site in sites:\n",
    "    to_mask_sequence[site-1] = \"<mask>\"\n",
    "masked_sequence = \"\".join(to_mask_sequence)\n",
    "masked_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data, masked_batch):\n",
    "    _, _, batch_tokens = batch_converter(data)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    batch_tokens = torch.concat((masked_batch, batch_tokens), dim=1)\n",
    "\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    logits = results['logits'][0][0]\n",
    "    logits = logits.cpu()\n",
    "    predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "    predicted_sequence = \"\".join([alphabet.all_toks[token_idx.item()] for token_idx in predicted_tokens])[1:]\n",
    "    predicted_fitness = float(GB1_data[GB1_data.full_sequence == predicted_sequence]['Fitness'].item())\n",
    "    return predicted_sequence, predicted_fitness\n",
    "\n",
    "def few_shot_prediction(masked_data, beat_wt_sequences, iters=3, context=5):\n",
    "    _, _, batch_tokens_mask = batch_converter(masked_data)\n",
    "    masked_batch = batch_tokens_mask[:, :, :-20]\n",
    "    masked_batch = masked_batch.to(device)\n",
    "\n",
    "    fits_avg = []\n",
    "    fits_max = []\n",
    "    old_preds = []\n",
    "    tot_fit = 0.0\n",
    "    max_fit = 0.0\n",
    "    for i in tqdm(range(context ** iters)):\n",
    "        full_data = [(f\"{j}\", seq) for j, seq in enumerate(np.random.choice(beat_wt_sequences, context, replace=False))]\n",
    "        try:\n",
    "            predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "        except:\n",
    "            predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "        max_fit = max(max_fit, predicted_fitness)\n",
    "        tot_fit += predicted_fitness\n",
    "        old_preds.append(predicted_sequence)\n",
    "    fits_avg.append(tot_fit / (context ** iters))\n",
    "    fits_max.append(max_fit)\n",
    "\n",
    "    new_preds = []\n",
    "    while len(old_preds) != 1:\n",
    "        tot_fit = 0.0\n",
    "        count = 0\n",
    "        max_fit = 0.0\n",
    "        while len(old_preds) != 0:\n",
    "            count += 1\n",
    "            full_data = [(f\"{j}\", old_preds.pop()) for j in range(context)]\n",
    "            try:\n",
    "                predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "            except:\n",
    "                predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "            max_fit = max(max_fit, predicted_fitness)\n",
    "            tot_fit += predicted_fitness\n",
    "            new_preds.append(predicted_sequence)\n",
    "        fits_avg.append(tot_fit / count)\n",
    "        fits_max.append(max_fit)\n",
    "        old_preds = new_preds\n",
    "        new_preds = []\n",
    "    return old_preds, np.array(fits_avg), np.array(fits_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mask = [\n",
    "    (\"GB1\", masked_sequence),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.51it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.54it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.54it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 225/225 [02:54<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n",
      "100%|██████████| 225/225 [02:54<00:00,  1.29it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:32<00:00,  1.20it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 400/400 [05:29<00:00,  1.21it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n",
      "100%|██████████| 625/625 [09:00<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# varying context length\n",
    "contexts = [5, 10, 15, 20, 25]\n",
    "iters = 2\n",
    "fitness_per_context_avg = []\n",
    "fitness_per_context_max = []\n",
    "for context in contexts:\n",
    "    curr_context_fitness_avg = np.array([0.0, 0.0, 0.0])\n",
    "    curr_context_fitness_max = np.array([0.0, 0.0, 0.0])\n",
    "    for trial in range(10):\n",
    "        final_pred, fitness_avg, fitness_max = few_shot_prediction(data_mask, GB1_data[GB1_data.Fitness > 1.0].full_sequence, iters, context)\n",
    "        curr_context_fitness_avg += fitness_avg\n",
    "        curr_context_fitness_max += fitness_max\n",
    "\n",
    "    curr_context_fitness_avg /= 10.0\n",
    "    curr_context_fitness_max /= 10.0\n",
    "\n",
    "    fitness_per_context_avg.append(curr_context_fitness_avg)\n",
    "    fitness_per_context_max.append(curr_context_fitness_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.1337431 , 1.74710995, 1.22521008]),\n",
       " array([2.04258572, 1.95656149, 1.46530294]),\n",
       " array([2.06059032, 2.31722678, 1.75491497]),\n",
       " array([2.14678006, 2.6657728 , 2.93525528]),\n",
       " array([2.18196093, 2.73182302, 2.90317318])]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_per_context_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5.91097697, 3.6112047 , 1.22521008]),\n",
       " array([5.95734381, 4.33668472, 1.46530294]),\n",
       " array([6.76436923, 5.22139873, 1.75491497]),\n",
       " array([6.67776499, 5.35068811, 2.93525528]),\n",
       " array([7.31623955, 4.9909823 , 2.90317318])]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_per_context_max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an increase at 20 context, so do more iterations there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prediction_iters(masked_data, beat_wt_sequences, iters=3, context=5):\n",
    "    _, _, batch_tokens_mask = batch_converter(masked_data)\n",
    "    masked_batch = batch_tokens_mask[:, :, :-20]\n",
    "    masked_batch = masked_batch.to(device)\n",
    "\n",
    "    fits_avg = []\n",
    "    fits_max = []\n",
    "    old_preds = []\n",
    "    tot_fit = 0.0\n",
    "    max_fit = 0.0\n",
    "    for i in tqdm(range(context ** 2)):\n",
    "        full_data = [(f\"{j}\", seq) for j, seq in enumerate(np.random.choice(beat_wt_sequences, context, replace=False))]\n",
    "        try:\n",
    "            predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "        except:\n",
    "            predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "        max_fit = max(max_fit, predicted_fitness)\n",
    "        tot_fit += predicted_fitness\n",
    "        old_preds.append(predicted_sequence)\n",
    "    fits_avg.append(tot_fit / (context ** iters))\n",
    "    fits_max.append(max_fit)\n",
    "\n",
    "    new_preds = []\n",
    "    for i in range(iters):\n",
    "        tot_fit = 0.0\n",
    "        max_fit = 0.0\n",
    "        while len(new_preds) != (context ** 2):\n",
    "            sample = np.random.choice(old_preds, context, replace=False)\n",
    "            full_data = [(f\"{j}\", samp) for j, samp in enumerate(sample)]\n",
    "            try:\n",
    "                predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "            except:\n",
    "                predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "            max_fit = max(max_fit, predicted_fitness)\n",
    "            tot_fit += predicted_fitness\n",
    "            new_preds.append(predicted_sequence)\n",
    "        fits_avg.append(tot_fit / (context ** 2))\n",
    "        fits_max.append(max_fit)\n",
    "        old_preds = new_preds\n",
    "        new_preds = []\n",
    "    \n",
    "    sample = np.random.choice(old_preds, context, replace=False)\n",
    "    full_data = [(f\"{j}\", samp) for j, samp in enumerate(sample)]\n",
    "    try:\n",
    "        predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "    except:\n",
    "        predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "    return predicted_sequence, predicted_fitness, np.array(fits_avg), np.array(fits_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:24<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "iters_pred, iters_fitness, iters_avg_fit, iters_max_fit = few_shot_prediction_iters(data_mask, GB1_data[(GB1_data.Fitness > 1.0)].full_sequence, iters=10, context = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGFSGEWTYDDATKTFTATE', 3.51664630346)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_pred, iters_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.31241451e-11, 2.79386615e+00, 3.29377146e+00, 3.82471291e+00,\n",
       "       3.51920806e+00, 3.51664630e+00, 3.51664630e+00, 3.51664630e+00,\n",
       "       3.51664630e+00, 3.51664630e+00, 3.51664630e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_avg_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.04207764, 5.44061457, 5.44061457, 5.44061457, 4.54135002,\n",
       "       3.5166463 , 3.5166463 , 3.5166463 , 3.5166463 , 3.5166463 ,\n",
       "       3.5166463 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_max_fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to converge on a prediction that is better than the average initial fitness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prediction_iters_weighted(masked_data, beat_wt_data, iters=3, context=5):\n",
    "    _, _, batch_tokens_mask = batch_converter(masked_data)\n",
    "    masked_batch = batch_tokens_mask[:, :, :-20]\n",
    "    masked_batch = masked_batch.to(device)\n",
    "\n",
    "    fits_avg = []\n",
    "    fits_max = []\n",
    "    old_preds = []\n",
    "    tot_fit = 0.0\n",
    "    max_fit = 0.0\n",
    "    for i in tqdm(range(context ** 2)):\n",
    "        weights = list(beat_wt_data.Fitness / beat_wt_data.Fitness.sum())\n",
    "        sample = np.random.choice(beat_wt_data.full_sequence, context, replace=False, p=weights)\n",
    "        full_data = [(f\"{j}\", seq) for j, seq in enumerate(sample)]\n",
    "        try:\n",
    "            predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "        except:\n",
    "            predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "        max_fit = max(max_fit, predicted_fitness)\n",
    "        tot_fit += predicted_fitness\n",
    "        old_preds.append([predicted_sequence, float(predicted_fitness)])\n",
    "    fits_avg.append(tot_fit / (context ** iters))\n",
    "    fits_max.append(max_fit)\n",
    "\n",
    "    new_preds = []\n",
    "    for i in tqdm(range(iters)):\n",
    "        tot_fit = 0.0\n",
    "        max_fit = 0.0\n",
    "        while len(new_preds) != (context ** 2):\n",
    "            old_preds = np.array(old_preds)\n",
    "            weights = old_preds[:, 1].astype(float) / np.sum(old_preds[:, 1].astype(float))\n",
    "            sample = np.random.choice(old_preds[:, 0], context, replace=False, p=weights)\n",
    "            full_data = [(f\"{j}\", samp) for j, samp in enumerate(sample)]\n",
    "            try:\n",
    "                predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "            except:\n",
    "                predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "            max_fit = max(max_fit, predicted_fitness)\n",
    "            tot_fit += predicted_fitness\n",
    "            new_preds.append([predicted_sequence, float(predicted_fitness)])\n",
    "        fits_avg.append(tot_fit / (context ** 2))\n",
    "        fits_max.append(max_fit)\n",
    "        old_preds = new_preds\n",
    "        new_preds = []\n",
    "    old_preds = np.array(old_preds)\n",
    "    weights = old_preds[:, 1].astype(float) / np.sum(old_preds[:, 1].astype(float))\n",
    "    sample = np.random.choice(old_preds[:, 0], context, replace=False, p=weights)\n",
    "    full_data = [(f\"{j}\", samp) for j, samp in enumerate(sample)]\n",
    "    try:\n",
    "        predicted_sequence, predicted_fitness = get_prediction(full_data, masked_batch)\n",
    "    except:\n",
    "        predicted_sequence, predicted_fitness = wildtype, 1.0\n",
    "    return predicted_sequence, predicted_fitness, np.array(fits_avg), np.array(fits_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted and limit search space to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:24<00:00,  1.23it/s]\n",
      "100%|██████████| 10/10 [53:55<00:00, 323.52s/it]\n"
     ]
    }
   ],
   "source": [
    "iters_pred_weighted, iters_fitness_weighted, iters_avg_fit_weighted, iters_max_fit_weighted = few_shot_prediction_iters_weighted(data_mask, GB1_data[(GB1_data['Fitness'] > 1.0) & (GB1_data['Fitness'] < 4.0)][['full_sequence', 'Fitness']], iters=10, context = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.61112654e-11, 4.41664563e+00, 5.16145244e+00, 5.44061457e+00,\n",
       "       5.44061457e+00, 5.44061457e+00, 5.44061457e+00, 5.44061457e+00,\n",
       "       5.44061457e+00, 5.44061457e+00, 5.44061457e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_avg_fit_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.76196566, 5.44061457, 5.44061457, 5.44061457, 5.44061457,\n",
       "       5.44061457, 5.44061457, 5.44061457, 5.44061457, 5.44061457,\n",
       "       5.44061457])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_max_fit_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.44061456678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters_fitness_weighted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, collater = load_model_and_alphabet('carp_38M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sequence_carp = masked_sequence.replace(\"<mask>\", '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNG###EWTYDDATKTFT#TE'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sequence_carp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = collater(masked_sequence_carp)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(x, logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model(collater(\"ABCD#DDE\")[0], logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sequence_carp.index('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.2644,  -0.9251,  -0.3768,  -0.2805,  -0.3468,   0.4952,  -0.7283,\n",
       "          -0.2962,  -0.3186,   0.5028,   3.4290,  -0.5135,  -0.2505,  -0.4270,\n",
       "           0.2813,   0.1844,  -0.1102,   0.2527,  -1.3649,  -0.5134,  -8.6467,\n",
       "          -8.9015,  -1.2752, -16.6647, -14.5850,  -9.1555, -16.6833, -16.7042,\n",
       "         -16.6712, -16.6683]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['logits'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.2644,  -0.9251,  -0.3768,  -0.2805,  -0.3468,   0.4952,  -0.7283,\n",
       "          -0.2962,  -0.3186,   0.5028,   3.4290,  -0.5135,  -0.2505,  -0.4270,\n",
       "           0.2813,   0.1844,  -0.1102,   0.2527,  -1.3649,  -0.5134,  -8.6467,\n",
       "          -8.9015,  -1.2752, -16.6647, -14.5850,  -9.1555, -16.6833, -16.7042,\n",
       "         -16.6712, -16.6683]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['logits'][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.2644,  -0.9251,  -0.3768,  -0.2805,  -0.3468,   0.4952,  -0.7283,\n",
       "          -0.2962,  -0.3186,   0.5028,   3.4290,  -0.5135,  -0.2505,  -0.4270,\n",
       "           0.2813,   0.1844,  -0.1102,   0.2527,  -1.3649,  -0.5134,  -8.6467,\n",
       "          -8.9015,  -1.2752, -16.6647, -14.5850,  -9.1555, -16.6833, -16.7042,\n",
       "         -16.6712, -16.6683]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['logits'][39]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What progress has been done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have preprocessed the data, implemented ESM for inference using the pretrained model, implemented functions to extract fitness from predicted variants, and have started to implement CARP.\n",
    "\n",
    "In addition to the above, we have done some research into how to fine-tune ESM for our purposes and also what other datasets we can bring in that could give us similar insights to GB1. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was little documentation on how to get the actual sequences out of the ESM model, so we used a combination of the internet and chat-gpt to get us through it and we think what we have makes sense. \n",
    "\n",
    "Additonally, getting models to work locally has been a challenge sine we both have M1/M2 macbooks which have some glitches with newer versions of pytorch and python. This also took a long time to debug. Later on, when we bring in larger ESM and CARP models and more data we will likely run it on the class cluster.\n",
    "\n",
    "Finally, We are having trouble finding documentation on doing masked sequence prediction with CARP and are currently researching more into this.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next steps are to implement fine-tuning for ESM so that we can run comparisons to the pre-trained and the fine-tuned ESM for different model sizes and get a wide range of comparisons.\n",
    "\n",
    "We are also working on finding other datasets to bring in to compare to the performance on the GB1 dataset.\n",
    "\n",
    "Finally, we are in the process of implementing Microsoft's CARP model for this task and will likely have it ready by early next week."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs144",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
